{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6626c2e7",
   "metadata": {},
   "source": [
    "Doing some basic data exploration on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360e6d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoga_poses:0 files\n",
      "test:0 files\n",
      "shoudler_stand:9 files\n",
      "traingle:10 files\n",
      "cobra:232 files\n",
      "dog:180 files\n",
      "chair:168 files\n",
      "no_pose:2 files\n",
      "tree:192 files\n",
      "warrior:218 files\n",
      "train:0 files\n",
      "shoudler_stand:50 files\n",
      "traingle:45 files\n",
      "cobra:400 files\n",
      "dog:400 files\n",
      "chair:400 files\n",
      "no_pose:26 files\n",
      "tree:418 files\n",
      "warrior:400 files\n"
     ]
    }
   ],
   "source": [
    "# get number of files in each directory of yoga_poses\n",
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "  file_counts = {}\n",
    "  for root, _, files in os.walk(directory):\n",
    "    file_counts[root] = len(files)\n",
    "  return file_counts\n",
    "\n",
    "# Usage\n",
    "yoga_poses_path = \"yoga_poses\"\n",
    "file_counts = count_files(yoga_poses_path)\n",
    "\n",
    "# Print the number of files in each directory\n",
    "for directory, count in file_counts.items():\n",
    "    name = directory.split(\"/\")[-1]\n",
    "    print(f\"{name}:{count} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78601a",
   "metadata": {},
   "source": [
    "We see that the dataset is imbalanced. We will have to use a script to scrape images and also use data augmentation to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83fbb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "622abfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None,alt_transform=None, augment_classes=None):\n",
    "        self.dataset = datasets.ImageFolder(root=root)\n",
    "        self.augment_classes = augment_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.dataset[index]\n",
    "\n",
    "        if self.augment_classes is not None and y in self.augment_classes:\n",
    "            x = self.transform(x)\n",
    "        else:\n",
    "            x = self.alt_transform(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f5e698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = datasets.ImageFolder(root=\"yoga_poses/train\", transform=transform)\n",
    "# test_dataset = datasets.ImageFolder(root=\"yoga_poses/test\", transform=transform)\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "alt_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db521824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "augment_classes = [0,1,5]\n",
    "train_dataset = CustomDataset(root=\"yoga_poses/train\", transform=transform, alt_transform=alt_transform, augment_classes=augment_classes)\n",
    "test_dataset = CustomDataset(root=\"yoga_poses/test\", transform=transform, alt_transform=alt_transform, augment_classes=augment_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7911c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43849ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2188, 1011)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565272f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e143f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
